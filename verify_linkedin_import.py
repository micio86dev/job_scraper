import asyncio
import logging
from scrapers.linkedin_scraper import LinkedInScraper
import sys

# Setup logging
logging.basicConfig(level=logging.INFO)


async def verify_import():
    print("ğŸš€ Starting LinkedIn Import Verification...")
    scraper = LinkedInScraper(max_results=1, fetch_details=True)

    # Search for a common job to ensure results
    keyword = "software engineer"
    location = "it"  # Italy

    print(f"ğŸ” Searching for '{keyword}' in '{location}'...")
    jobs = await scraper.scrape(keyword, location)

    if not jobs:
        print("âŒ No jobs found. Try different keywords/location or check network.")
        return

    job = jobs[0]
    print(f"âœ… Found job: {job['title']} at {job['company']['name']}")
    print(f"ğŸ”— ID: {job['external_id']}")

    print("\nâ³ Fetching full details (Description)...")
    details = await scraper.fetch_job_details(job["external_id"])

    if not details:
        print("âŒ Failed to fetch details.")
        return

    description = details["description"]

    print("\n" + "=" * 60)
    print("ğŸ“ PROCESSED MARKDOWN DESCRIPTION")
    print("=" * 60)
    print(description)
    print("=" * 60 + "\n")

    # Validation Checks
    print("ğŸ“Š Verification Checks:")

    # Check 1: Is it Markdown? (Simple heuristic)
    is_markdown = "#" in description or "*" in description or "-" in description
    print(f"[{'âœ…' if is_markdown else 'âŒ'}] Is Markdown format")

    unwanted_phrases = [
        "Show more",
        "Show less",
        "Referrals increase your chances",
        "See who you know",
        "Sign in to create job alert",
        "Similar jobs",
        "Similar Searches",
        "People also viewed",
        "Explore collaborative articles",
    ]

    found_unwanted = []
    for phrase in unwanted_phrases:
        if phrase.lower() in description.lower():
            found_unwanted.append(phrase)

    print(f"[{'âœ…' if not found_unwanted else 'âŒ'}] No unwanted phrases found")
    if found_unwanted:
        print(f"   âš ï¸ Found: {found_unwanted}")

    # Check 3: No HTML tags (basic check)
    import re

    has_html = bool(re.search(r"<div|<span|<ul|<li|<button", description))
    print(f"[{'âœ…' if not has_html else 'âŒ'}] No major HTML tags remaining")

    # Check 4: H1 demoted to H2 (Check if line starts with single # )
    has_h1 = bool(re.search(r"^#\s", description, re.MULTILINE))
    print(f"[{'âœ…' if not has_h1 else 'âŒ'}] No H1 headers (SEO)")


if __name__ == "__main__":
    asyncio.run(verify_import())
